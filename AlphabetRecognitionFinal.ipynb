{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Alphabet Recognition System using Convolutional Neural Network (CNN)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convolutional Neural Network (CNN) is a Deep Learning Algorithm widely used for character recognition. This algorithm identifies the alphabet from the given input image.\n",
    "\n",
    "The accuracy achieved using this algorithm is 93.42%.\n",
    "\n",
    "## 1. Anvil Integration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import anvil.server\r\n",
    "import anvil.media\r\n",
    "anvil.server.connect(\"44STZQZQTYAAVHHWGRPMXDRN-P5VUQGPD3HW5UMWJ\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Authenticated OK\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Importing Libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "# import matplotlib.pyplot as plt\r\n",
    "from keras.preprocessing.image import ImageDataGenerator\r\n",
    "from keras.preprocessing import image\r\n",
    "import keras\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation\r\n",
    "import os\r\n",
    "import pickle"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\TIMILE~1\\AppData\\Local\\Temp/ipykernel_5904/1726067530.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Defining the Model Architecture"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "model = Sequential()\r\n",
    "model.add(Conv2D(32, (3, 3), input_shape = (32,32,3), activation = 'relu'))\r\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\r\n",
    "\r\n",
    "\r\n",
    "model.add(Conv2D(32, (3, 3), activation = 'relu'))\r\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\r\n",
    "\r\n",
    "model.add(Flatten())\r\n",
    "model.add(Dense(units = 128, activation = 'relu'))\r\n",
    "model.add(Dense(units = 26, activation = 'softmax'))\r\n",
    "\r\n",
    "\r\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\r\n",
    "\r\n",
    "model.summary()\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\TIMILE~1\\AppData\\Local\\Temp/ipykernel_10500/525130724.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Importing the Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\r\n",
    "                                   shear_range = 0.2,\r\n",
    "                                   zoom_range = 0.2,\r\n",
    "                                   horizontal_flip = True)\r\n",
    "\r\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\r\n",
    "\r\n",
    "train_generator = train_datagen.flow_from_directory(\r\n",
    "    directory = 'Training',\r\n",
    "    target_size = (32,32),\r\n",
    "    batch_size = 32,\r\n",
    "    class_mode = 'categorical'\r\n",
    "\r\n",
    ")\r\n",
    "\r\n",
    "test_generator = test_datagen.flow_from_directory(\r\n",
    "    directory = 'Testing',\r\n",
    "    target_size = (32,32),\r\n",
    "    batch_size = 32,\r\n",
    "    class_mode = 'categorical'\r\n",
    "\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 501 images belonging to 26 classes.\n",
      "Found 260 images belonging to 26 classes.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Training the Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# history = model.fit_generator(train_generator,\r\n",
    "#                          steps_per_epoch = 16,\r\n",
    "#                          epochs = 3,\r\n",
    "#                          validation_data = test_generator,\r\n",
    "#                          validation_steps = 16)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.1866 - accuracy: 0.9082 - val_loss: 0.7112 - val_accuracy: 0.8657\n",
      "Epoch 2/3\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.1769 - accuracy: 0.9301 - val_loss: 0.4118 - val_accuracy: 0.8662\n",
      "Epoch 3/3\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.1672 - accuracy: 0.9261 - val_loss: 0.2001 - val_accuracy: 0.9342\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Saving/Loading the Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "pickle.dump(model, open('CNN_model.sav', 'wb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "model = pickle.load(open('CNN_model.sav','rb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 7. Testing the Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# def get_result(result):\r\n",
    "#     if result[0][0] == 1:\r\n",
    "#         return('a')\r\n",
    "#     elif result[0][1] == 1:\r\n",
    "#         return ('b')\r\n",
    "#     elif result[0][2] == 1:\r\n",
    "#         return ('c')\r\n",
    "#     elif result[0][3] == 1:\r\n",
    "#         return ('d')\r\n",
    "#     elif result[0][4] == 1:\r\n",
    "#         return ('e')\r\n",
    "#     elif result[0][5] == 1:\r\n",
    "#         return ('f')\r\n",
    "#     elif result[0][6] == 1:\r\n",
    "#         return ('g')\r\n",
    "#     elif result[0][7] == 1:\r\n",
    "#         return ('h')\r\n",
    "#     elif result[0][8] == 1:\r\n",
    "#         return ('i')\r\n",
    "#     elif result[0][9] == 1:\r\n",
    "#         return ('j')\r\n",
    "#     elif result[0][10] == 1:\r\n",
    "#         return ('k')\r\n",
    "#     elif result[0][11] == 1:\r\n",
    "#         return ('l')\r\n",
    "#     elif result[0][12] == 1:\r\n",
    "#         return ('m')\r\n",
    "#     elif result[0][13] == 1:\r\n",
    "#         return ('n')\r\n",
    "#     elif result[0][14] == 1:\r\n",
    "#         return ('o')\r\n",
    "#     elif result[0][15] == 1:\r\n",
    "#         return ('p')\r\n",
    "#     elif result[0][16] == 1:\r\n",
    "#         return ('q')\r\n",
    "#     elif result[0][17] == 1:\r\n",
    "#         return ('r')\r\n",
    "#     elif result[0][18] == 1:\r\n",
    "#         return ('s')\r\n",
    "#     elif result[0][19] == 1:\r\n",
    "#         return ('t')\r\n",
    "#     elif result[0][20] == 1:\r\n",
    "#         return ('u')\r\n",
    "#     elif result[0][21] == 1:\r\n",
    "#         return ('v')\r\n",
    "#     elif result[0][22] == 1:\r\n",
    "#         return ('w')\r\n",
    "#     elif result[0][23] == 1:\r\n",
    "#         return ('x')\r\n",
    "#     elif result[0][24] == 1:\r\n",
    "#         return ('y')\r\n",
    "#     elif result[0][25] == 1:\r\n",
    "#         return ('z')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# filename = r'Testing\\e\\25.png'\r\n",
    "# test_image = image.load_img(filename, target_size = (32,32))\r\n",
    "# plt.imshow(test_image)\r\n",
    "# test_image = image.img_to_array(test_image)\r\n",
    "# test_image = np.expand_dims(test_image, axis = 0)\r\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "# result = model.predict(test_image)\r\n",
    "# result = get_result(result)\r\n",
    "# print ('Predicted Alphabet is: {}'.format(result))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Predicted Alphabet is: e\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. Predicting the Alphabet from the Input Image"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This part of code is receives the input image from the anvil website and returns the predicted alphabet back to the website."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "# @anvil.server.callable\r\n",
    "# def model_run(path):\r\n",
    "#     with anvil.media.TempFile(path) as filename:\r\n",
    "#         test_image = image.load_img(filename, target_size = (32,32))\r\n",
    "#         test_image = image.img_to_array(test_image)\r\n",
    "#         test_image = np.expand_dims(test_image, axis = 0)\r\n",
    "#         result = model.predict(test_image)\r\n",
    "#         result = get_result(result)\r\n",
    "#         return ('Predicted Alphabet is: {}'.format(result))\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "interpreter": {
   "hash": "cf758511affad3b101537e95bf7c607b4798ea5486a1c8866b13c65bf2f3e9df"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}